# PhÃ¢n TÃ­ch Cáº¥u TrÃºc Há»‡ Thá»‘ng Real-Time Stock Analytics

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng nÃ y lÃ  má»™t **pipeline xá»­ lÃ½ dá»¯ liá»‡u real-time** cho viá»‡c thu tháº­p, lÆ°u trá»¯ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chá»©ng khoÃ¡n tá»« API Finnhub. Há»‡ thá»‘ng sá»­ dá»¥ng kiáº¿n trÃºc **event-driven** vá»›i Kafka lÃ m message broker vÃ  Ã¡p dá»¥ng mÃ´ hÃ¬nh **Medallion Architecture** (Bronze-Silver-Gold) cho data warehouse.

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Finnhub    â”‚  (External API)
â”‚    API      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP Request (má»—i 6 giÃ¢y)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer      â”‚  (Python - Kafka Producer)
â”‚  producer.py    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Kafka Message
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kafka       â”‚  (Message Broker)
â”‚  Topic: stock-  â”‚
â”‚     quotes      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Consume
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Consumer      â”‚  (Python - Kafka Consumer)
â”‚  consumer.py    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ JSON Files
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MinIO       â”‚  (Object Storage - S3 Compatible)
â”‚ bronze-trans-   â”‚
â”‚   actions/      â”‚
â”‚ {symbol}/{ts}.  â”‚
â”‚     json        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Airflow DAG (má»—i 1 phÃºt)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Apache        â”‚  (Workflow Orchestration)
â”‚   Airflow       â”‚
â”‚  DAG: minio_to_ â”‚
â”‚  bigquery_multi â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Incremental Load
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BigQuery      â”‚  (Data Warehouse)
â”‚  Dataset: stock â”‚
â”‚  - bronze_      â”‚
â”‚    stock_quotes â”‚
â”‚    _raw         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ dbt Transform
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      dbt        â”‚  (Data Transformation)
â”‚  dbt_stocks/    â”‚
â”‚  Bronze â†’ Silverâ”‚
â”‚  â†’ Gold         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BigQuery      â”‚  (Analytics Layer)
â”‚  - silver_      â”‚
â”‚    stock_quotes â”‚
â”‚  - gold_kpi     â”‚
â”‚  - gold_candle- â”‚
â”‚    stick        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ CÃ¡c ThÃ nh Pháº§n ChÃ­nh

### 1. **Data Ingestion Layer**

#### 1.1 Producer (`infra/producer/producer.py`)
- **Chá»©c nÄƒng**: Thu tháº­p dá»¯ liá»‡u real-time tá»« Finnhub API
- **CÃ´ng nghá»‡**: Python, Kafka Producer, Requests
- **Hoáº¡t Ä‘á»™ng**:
  - Fetch quote cho 5 symbols: AAPL, MSFT, TSLA, GOOGL, AMZN
  - Gá»­i message vÃ o Kafka topic `stock-quotes` má»—i 6 giÃ¢y
  - Format: JSON vá»›i cÃ¡c field: `c`, `d`, `dp`, `h`, `l`, `o`, `pc`, `t`, `symbol`, `fetched_at`

#### 1.2 Consumer (`infra/consumer/consumer.py`)
- **Chá»©c nÄƒng**: Consume messages tá»« Kafka vÃ  lÆ°u vÃ o MinIO
- **CÃ´ng nghá»‡**: Python, Kafka Consumer, Boto3 (S3 API)
- **Hoáº¡t Ä‘á»™ng**:
  - Consume tá»« topic `stock-quotes`
  - LÆ°u file JSON vÃ o MinIO bucket `bronze-transactions`
  - Cáº¥u trÃºc key: `{symbol}/{timestamp}.json`
  - Group ID: `bronze-Consumer` (Ä‘áº£m báº£o khÃ´ng máº¥t message)

---

### 2. **Infrastructure Layer (Docker Compose)**

#### 2.1 Services Containerized

**Kafka Ecosystem:**
- **Zookeeper**: Quáº£n lÃ½ metadata vÃ  coordination cho Kafka
- **Kafka**: Message broker (ports: 9092, 29092)
- **Kafdrop**: Web UI Ä‘á»ƒ monitor Kafka topics (port: 9000)

**Storage:**
- **MinIO**: S3-compatible object storage
  - Console: port 9001
  - API: port 9002
  - Credentials: admin/password123

**Orchestration:**
- **PostgreSQL**: Metadata database cho Airflow
- **Airflow Webserver**: Web UI (port: 8080)
- **Airflow Scheduler**: Cháº¡y DAGs theo schedule
- **Airflow Init**: Khá»Ÿi táº¡o database vÃ  admin user

**Monitoring:**
- **Grafana**: Dashboard vÃ  visualization (port: 3000)

---

### 3. **Data Pipeline Layer (Airflow)**

#### 3.1 DAG: `minio_to_bigquery_multi`
- **Schedule**: Má»—i 1 phÃºt (`* * * * *`)
- **Chá»©c nÄƒng**: Incremental load tá»« MinIO vÃ o BigQuery

**Tasks cho má»—i symbol:**
1. **`download_{symbol}`**: 
   - Download chá»‰ cÃ¡c file má»›i tá»« MinIO (dá»±a trÃªn `last_ts` trong metadata table)
   - Sá»­ dá»¥ng pagination Ä‘á»ƒ xá»­ lÃ½ >1000 objects
   - Sort files theo timestamp Ä‘á»ƒ trÃ¡nh out-of-order
   - Push danh sÃ¡ch files vÃ  max_ts vÃ o XCom

2. **`load_{symbol}`**:
   - Load JSON files vÃ o BigQuery table `bronze_stock_quotes_raw`
   - Sá»­ dá»¥ng `insert_rows_json` Ä‘á»ƒ batch insert
   - Update metadata table `metadata_last_ts` sau khi load thÃ nh cÃ´ng

**TÃ­nh nÄƒng quan trá»ng:**
- **Incremental loading**: Chá»‰ load files má»›i dá»±a trÃªn timestamp
- **Metadata tracking**: LÆ°u `last_ts` Ä‘á»ƒ trÃ¡nh duplicate
- **Parallel processing**: Xá»­ lÃ½ 5 symbols song song
- **Error handling**: Retry logic vÃ  error logging

---

### 4. **Data Warehouse Layer (BigQuery)**

#### 4.1 Project & Dataset
- **Project**: `real-time-stock-analytics-25`
- **Dataset**: `stock`
- **Tables**:
  - `bronze_stock_quotes_raw`: Raw data tá»« MinIO
  - `metadata_last_ts`: Tracking metadata cho incremental load

---

### 5. **Data Transformation Layer (dbt)**

#### 5.1 MÃ´ hÃ¬nh Medallion Architecture

**Bronze Layer** (`dbt_stocks/models/bronze/`)
- **`bronze_stock_quotes.sql`**: 
  - Materialized: `view`
  - Rename columns tá»« raw format (c, d, dp, h, l, o, pc, t) sang tÃªn cÃ³ Ã½ nghÄ©a
  - Schema: `bronze`

**Silver Layer** (`dbt_stocks/models/silver/`)
- **`silver_stock_quotes.sql`**:
  - Materialized: `incremental` (merge strategy)
  - Data quality: Type casting, validation (price > 0, high >= low)
  - Deduplication: ROW_NUMBER() Ä‘á»ƒ loáº¡i bá» duplicate
  - Timestamp conversion: Epoch seconds â†’ TIMESTAMP (UTC & US timezone)
  - Unique key: `[symbol, market_timestamp_raw]`
  - Incremental filter: Chá»‰ load records chÆ°a cÃ³ trong Silver

**Gold Layer** (`dbt_stocks/models/gold/`)

1. **`gold_kpi.sql`**:
   - Materialized: `table`
   - Latest KPI cho má»—i symbol (ROW_NUMBER() ORDER BY fetched_at DESC)
   - Columns: current_price, change_amount, change_percent, day_open, day_high, day_low, prev_close

2. **`gold_kpi_latest.sql`**:
   - Materialized: `view`
   - Latest KPI tá»« history table (dá»±a trÃªn market_time_utc)

3. **`gold_kpi_history.sql`**:
   - Materialized: `incremental` (merge strategy)
   - LÆ°u toÃ n bá»™ lá»‹ch sá»­ KPI theo thá»i gian
   - Unique key: `[symbol, market_time_utc]`

4. **`gold_candlestick.sql`**:
   - Materialized: `table`
   - Aggregate dá»¯ liá»‡u thÃ nh candlestick chart (OHLC) theo ngÃ y
   - Window functions Ä‘á»ƒ tÃ­nh OPEN (first value) vÃ  CLOSE (last value)
   - Láº¥y 12 ngÃ y gáº§n nháº¥t cho má»—i symbol
   - Columns: candle_date, candle_open, candle_high, candle_low, candle_close, trend_line

5. **`gold_treechart.sql`**:
   - Materialized: `table`
   - TÃ­nh toÃ¡n volatility vÃ  average price cho visualization dáº¡ng tree chart
   - Láº¥y giÃ¡ trung bÃ¬nh cá»§a ngÃ y má»›i nháº¥t
   - TÃ­nh volatility (standard deviation) vÃ  relative volatility
   - Columns: symbol, avg_price, volatility, relative_volatility

---

## ğŸ“Š Data Flow Chi Tiáº¿t

### Real-Time Flow (6 giÃ¢y/láº§n)
```
Finnhub API â†’ Producer â†’ Kafka â†’ Consumer â†’ MinIO
```

### Batch Processing Flow (1 phÃºt/láº§n)
```
MinIO â†’ Airflow DAG â†’ BigQuery Bronze â†’ dbt Silver â†’ dbt Gold
```

### Data Transformation Flow
```
Raw JSON (MinIO)
    â†“
Bronze (BigQuery - View)
    â†“ Rename columns
Silver (BigQuery - Incremental Table)
    â†“ Type casting, validation, deduplication
Gold (BigQuery - Tables/Views)
    â†“ Aggregation, KPI calculation
Analytics & Dashboards
```

---

## ğŸ” Configuration & Credentials

### MinIO
- Endpoint: `http://minio:9000` (internal), `http://localhost:9002` (external)
- Access Key: `admin`
- Secret Key: `password123`
- Bucket: `bronze-transactions`

### Kafka
- Bootstrap Servers: `localhost:29092` (external), `kafka:9092` (internal)
- Topic: `stock-quotes`
- Consumer Group: `bronze-Consumer`

### BigQuery
- Project: `real-time-stock-analytics-25`
- Dataset: `stock`
- Credentials: `infra/airflow_gcp_key.json` (mounted vÃ o Airflow containers)

### Finnhub API
- API Key: `d4139g9r01qr2l0cd2v0d4139g9r01qr2l0cd2vg`
- Endpoint: `https://finnhub.io/api/v1/quote`
- Rate Limit: 60 calls/minute (5 symbols Ã— 12 calls/min = 60)

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
real-time-stock/
â”œâ”€â”€ infra/                          # Infrastructure code
â”‚   â”œâ”€â”€ dags/                       # Airflow DAGs
â”‚   â”‚   â””â”€â”€ minio_to_bigquery_multi.py
â”‚   â”œâ”€â”€ producer/                   # Kafka Producer
â”‚   â”‚   â””â”€â”€ producer.py
â”‚   â”œâ”€â”€ consumer/                   # Kafka Consumer
â”‚   â”‚   â””â”€â”€ consumer.py
â”‚   â”œâ”€â”€ docker-compose.yml          # Container orchestration
â”‚   â”œâ”€â”€ Dockerfile                  # Custom Airflow image
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ airflow_gcp_key.json        # GCP credentials
â”‚
â”œâ”€â”€ dbt_stocks/                     # dbt project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bronze/                 # Bronze layer
â”‚   â”‚   â”‚   â”œâ”€â”€ bronze_stock_quotes.sql
â”‚   â”‚   â”‚   â””â”€â”€ sources.yml
â”‚   â”‚   â”œâ”€â”€ silver/                 # Silver layer
â”‚   â”‚   â”‚   â””â”€â”€ silver_stock_quotes.sql
â”‚   â”‚   â””â”€â”€ gold/                   # Gold layer
â”‚   â”‚       â”œâ”€â”€ gold_kpi.sql
â”‚   â”‚       â”œâ”€â”€ gold_kpi_latest.sql
â”‚   â”‚       â”œâ”€â”€ gold_kpi_history.sql
â”‚   â”‚       â”œâ”€â”€ gold_candlestick.sql
â”‚   â”‚       â””â”€â”€ gold_treechart.sql
â”‚   â”œâ”€â”€ dbt_project.yml             # dbt configuration
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ requirements.txt                # Root dependencies
â”œâ”€â”€ logs/                           # Application logs
â””â”€â”€ venv312/                        # Python virtual environment
```

---

## ğŸ¯ Äiá»ƒm Máº¡nh cá»§a Há»‡ Thá»‘ng

1. **Scalability**: 
   - Kafka cho phÃ©p scale consumer/producer Ä‘á»™c láº­p
   - Airflow DAG xá»­ lÃ½ parallel cho nhiá»u symbols
   - BigQuery tá»± Ä‘á»™ng scale theo workload

2. **Reliability**:
   - Kafka Ä‘áº£m báº£o message khÃ´ng bá»‹ máº¥t
   - Incremental loading vá»›i metadata tracking
   - Retry logic trong Airflow

3. **Data Quality**:
   - Validation á»Ÿ Silver layer
   - Deduplication logic
   - Type casting vÃ  normalization

4. **Separation of Concerns**:
   - Medallion Architecture (Bronze-Silver-Gold)
   - Clear separation giá»¯a ingestion, storage, transformation

5. **Monitoring**:
   - Kafdrop cho Kafka monitoring
   - Airflow UI cho pipeline monitoring
   - Grafana cho visualization

---

## ğŸ”„ Workflow Execution

### 1. Producer (Cháº¡y liÃªn tá»¥c)
```bash
python infra/producer/producer.py
```
- Fetch data má»—i 6 giÃ¢y
- Gá»­i vÃ o Kafka topic

### 2. Consumer (Cháº¡y liÃªn tá»¥c)
```bash
python infra/consumer/consumer.py
```
- Consume tá»« Kafka
- LÆ°u vÃ o MinIO

### 3. Airflow (Tá»± Ä‘á»™ng cháº¡y)
- Scheduler cháº¡y DAG má»—i 1 phÃºt
- Download vÃ  load incremental data

### 4. dbt (Cháº¡y thá»§ cÃ´ng hoáº·c schedule)
```bash
cd dbt_stocks
dbt run
```
- Transform Bronze â†’ Silver â†’ Gold

---

## ğŸ“ˆ Performance Characteristics

- **Latency**: 
  - Real-time ingestion: ~6 giÃ¢y
  - Batch processing: ~1 phÃºt
  - End-to-end: ~1-2 phÃºt tá»« API Ä‘áº¿n Gold layer

- **Throughput**:
  - 5 symbols Ã— 10 messages/phÃºt = 50 messages/phÃºt
  - ~3000 messages/giá»
  - ~72,000 messages/ngÃ y

- **Storage**:
  - MinIO: JSON files (temporary storage)
  - BigQuery: Compressed columnar storage (long-term)

---

## ğŸ› ï¸ Technologies Stack

| Layer | Technology |
|-------|-----------|
| Message Broker | Apache Kafka |
| Object Storage | MinIO (S3-compatible) |
| Orchestration | Apache Airflow |
| Data Warehouse | Google BigQuery |
| Transformation | dbt (Data Build Tool) |
| Monitoring | Kafdrop, Grafana |
| Database | PostgreSQL (Airflow metadata) |
| Language | Python 3.12 |

---

## ğŸ” Monitoring & Observability

1. **Kafdrop** (http://localhost:9000): Monitor Kafka topics, messages, consumer groups
2. **Airflow UI** (http://localhost:8080): Monitor DAG runs, task status, logs
3. **Grafana** (http://localhost:3000): Custom dashboards vÃ  metrics
4. **BigQuery Console**: Query performance, storage usage

---

## ğŸš€ Deployment

Há»‡ thá»‘ng Ä‘Æ°á»£c containerized hoÃ n toÃ n vá»›i Docker Compose:
```bash
cd infra
docker-compose up -d
```

Services sáº½ tá»± Ä‘á»™ng start theo thá»© tá»± dependencies.

---

## ğŸ“ Notes

- Há»‡ thá»‘ng Ä‘ang cháº¡y á»•n Ä‘á»‹nh vá»›i pipeline real-time
- Incremental loading giÃºp tá»‘i Æ°u performance vÃ  cost
- Medallion Architecture Ä‘áº£m báº£o data quality vÃ  traceability
- CÃ³ thá»ƒ scale báº±ng cÃ¡ch thÃªm symbols hoáº·c tÄƒng frequency

